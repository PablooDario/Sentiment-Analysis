{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7zNeOiGGx96"
      },
      "source": [
        "# Interfaz Gráfica para Predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YW1PN3X9Az3f"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kBN6LYny8nYh"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3Qwj1URG5wI"
      },
      "source": [
        "### Creamos el esqueleto del modelo para cargarlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pxb9aUNm8YBl"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # LSTM\n",
        "    self.lstm = nn.LSTM(\n",
        "        input_size,\n",
        "        hidden_size,\n",
        "        num_layers,\n",
        "        dropout=dropout,\n",
        "        batch_first=True\n",
        "    )\n",
        "\n",
        "    # Layer Normalization\n",
        "    self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, hidden_size // 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_size // 2, hidden_size//4),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_size//4, output_size)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    if len(x.shape) == 2:\n",
        "        x = x.unsqueeze(1)  # Agrega dimensión de secuencia (batch_size, 1, embedding_dim)\n",
        "\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "    # LSTM output: output of all the hidden_state, hidde_state, cell_state\n",
        "    lstm_out, (hidden, _) = self.lstm(x, (h0, c0))\n",
        "\n",
        "    # Apply Layer Normalization to the last output of the LSTM\n",
        "    lstm_out_norm = self.layer_norm(lstm_out[:, -1, :])\n",
        "\n",
        "    # Classification layers\n",
        "    output = self.classifier(lstm_out_norm)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMl1qosSHB_A"
      },
      "source": [
        "#### Función para cargar el modelo guardado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cxc81SHf8tCI"
      },
      "outputs": [],
      "source": [
        "def cargar_modelo():\n",
        "    embedding_dim = 768  # Embedding size\n",
        "    hidden_dim = 256\n",
        "    output_dim = 6  # Number of emotion or classes\n",
        "    num_layers = 2\n",
        "    dropout = 0.3\n",
        "\n",
        "    # Model\n",
        "    model = LSTM(embedding_dim, hidden_dim, num_layers, output_dim, dropout)\n",
        "    model.load_state_dict(torch.load('model/modelo_emociones.pth', map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95EPLFOc80GU"
      },
      "source": [
        "## Preprocesamiento y vectorizacion del Texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R5YCEOny85yY"
      },
      "outputs": [],
      "source": [
        "def procesar_texto(text):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "    model = AutoModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        outputs = model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrqLEMbNBcNk"
      },
      "source": [
        "## Predecir la emocion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ERe2Ho3zA6Yu"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "    # Obtener los embeddings\n",
        "    embeddings = procesar_texto(text)\n",
        "    # Carga el modelo\n",
        "    model = cargar_modelo()\n",
        "    # Predicción\n",
        "    with torch.no_grad():\n",
        "        output = model(embeddings)\n",
        "    probabilities = F.softmax(output, dim=1).squeeze().tolist()\n",
        "\n",
        "    label_mapping = {\n",
        "        0: \"sadness\",\n",
        "        1: \"joy\",\n",
        "        2: \"love\",\n",
        "        3: \"anger\",\n",
        "        4: \"fear\",\n",
        "        5: \"surprise\"\n",
        "    }\n",
        "\n",
        "    # Obtener la clase con la mayor probabilidad\n",
        "    predicted_index = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    # Genera un diccionario con las etiquetas y sus probabilidades\n",
        "    probabilities_dict = {label_mapping[i]: prob for i, prob in enumerate(probabilities)}\n",
        "\n",
        "    return probabilities_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYGxH8xIBeD_"
      },
      "source": [
        "## Interfaz Grafica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "-eNu9e8nDO7Z",
        "outputId": "1c7638da-33a6-4e02-99f2-eb252f417ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7862\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define la interfaz\n",
        "interface = gr.Interface(\n",
        "    fn=predict_sentiment,  # Función de predicción\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Escribe tu texto aquí...\"),\n",
        "    outputs=gr.Label(num_top_classes=6),  # Muestra todas las clases con probabilidades\n",
        "    title=\"Análisis de Sentimientos\",\n",
        "    description=\"Ingresa un texto para analizar su sentimiento y ver la probabilidad de cada clase.\"\n",
        ")\n",
        "\n",
        "# Lanza la aplicación\n",
        "interface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
