{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuned Based Models for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisdogo/miniconda3/envs/sentiment-deep_learning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-06 01:41:10.875742: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-06 01:41:10.953439: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Embeddings & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = joblib.load('data/train_embeddings.pkl')\n",
    "y_train = pd.read_csv('data/training.csv')['label'].values\n",
    "\n",
    "X_val = joblib.load('data/validation_embeddings.pkl')\n",
    "y_val = pd.read_csv('data/validation.csv')['label'].values\n",
    "\n",
    "X_test = joblib.load('data/test_embeddings.pkl')\n",
    "y_test = pd.read_csv('data/test.csv')['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 768) (16000,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(type(X_train), type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Dataframe into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset): # defines how the text is pre-processed before sending it to the neural network.\n",
    "    # generates \n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings  # Lista de embeddings generados por RoBERTa\n",
    "        self.labels = labels.squeeze()  # Lista de etiquetas\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx): # []\n",
    "        return torch.tensor(self.embeddings[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.EmotionDataset'> <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "# Dataset type conversion\n",
    "train_dataset = EmotionDataset(X_train, y_train)\n",
    "val_dataset = EmotionDataset(X_val, y_val)\n",
    "test_dataset = EmotionDataset(X_test, y_test)\n",
    "\n",
    "# will feed the data in batches to the neural network for suitable training and processing.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(type(train_dataset), type(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT model\n",
    "\n",
    "Parameters:\n",
    "- Input_size: Embedding length\n",
    "- Heads: Number of heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 6)  # Classifier layer in top of the model\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        output_2 = self.l2(embeddings)\n",
    "        output = self.l3(output_2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "LEARNING_RATE = .01\n",
    "EPOCHS = 10\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    loss_history = []\n",
    "    model.train()\n",
    "    for _, data in enumerate(train_loader, 0):\n",
    "        # Unpack the data from the DataLoader\n",
    "        embeddings, targets = data\n",
    "        embeddings = embeddings.to(device, dtype=torch.float32)  # Move embeddings to the device\n",
    "        targets = targets.to(device, dtype=torch.long)  # Move targets to the device\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(embeddings)\n",
    "\n",
    "        # Calculate loss\n",
    "        optimizer.zero_grad()\n",
    "        # One-hot encoding\n",
    "        one_hot = torch.nn.functional.one_hot(targets, num_classes=6).float() # loss function needs it like this, idk\n",
    "        loss = loss_fn(outputs, one_hot)\n",
    "        loss_history.append(loss.detach())\n",
    "        if _ % 5000 == 0:  # Print loss for every 5000 steps\n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.7629598379135132\n",
      "Epoch: 1, Loss: 1.165524959564209\n",
      "Epoch: 2, Loss: 0.9943251013755798\n",
      "Epoch: 3, Loss: 1.0869170427322388\n",
      "Epoch: 4, Loss: 1.3888359069824219\n",
      "Epoch: 5, Loss: 1.1776103973388672\n",
      "Epoch: 6, Loss: 1.442686676979065\n",
      "Epoch: 7, Loss: 0.787227988243103\n",
      "Epoch: 8, Loss: 1.5459790229797363\n",
      "Epoch: 9, Loss: 1.3632638454437256\n",
      "Epoch: 10, Loss: 1.7111494541168213\n",
      "Epoch: 11, Loss: 0.8610047101974487\n",
      "Epoch: 12, Loss: 0.7785718441009521\n",
      "Epoch: 13, Loss: 1.6410508155822754\n",
      "Epoch: 14, Loss: 1.010100245475769\n",
      "Epoch: 15, Loss: 1.3328192234039307\n",
      "Epoch: 16, Loss: 1.7329339981079102\n",
      "Epoch: 17, Loss: 1.5961849689483643\n",
      "Epoch: 18, Loss: 1.3418307304382324\n",
      "Epoch: 19, Loss: 1.6282483339309692\n",
      "Epoch: 20, Loss: 1.4765093326568604\n",
      "Epoch: 21, Loss: 0.8197331428527832\n",
      "Epoch: 22, Loss: 1.3600597381591797\n",
      "Epoch: 23, Loss: 1.3956938982009888\n",
      "Epoch: 24, Loss: 1.3879404067993164\n",
      "Epoch: 25, Loss: 1.1671992540359497\n",
      "Epoch: 26, Loss: 1.7250717878341675\n",
      "Epoch: 27, Loss: 1.6508972644805908\n",
      "Epoch: 28, Loss: 1.583367943763733\n",
      "Epoch: 29, Loss: 1.299626111984253\n",
      "Epoch: 30, Loss: 1.333582878112793\n",
      "Epoch: 31, Loss: 1.0699235200881958\n",
      "Epoch: 32, Loss: 1.021607756614685\n",
      "Epoch: 33, Loss: 1.331935167312622\n",
      "Epoch: 34, Loss: 1.1575456857681274\n",
      "Epoch: 35, Loss: 1.1532812118530273\n",
      "Epoch: 36, Loss: 1.3522753715515137\n",
      "Epoch: 37, Loss: 1.4773482084274292\n",
      "Epoch: 38, Loss: 1.255051851272583\n",
      "Epoch: 39, Loss: 1.774430274963379\n",
      "Epoch: 40, Loss: 1.6602588891983032\n",
      "Epoch: 41, Loss: 1.3288350105285645\n",
      "Epoch: 42, Loss: 0.909494161605835\n",
      "Epoch: 43, Loss: 0.665123462677002\n",
      "Epoch: 44, Loss: 1.2948713302612305\n",
      "Epoch: 45, Loss: 1.3107271194458008\n",
      "Epoch: 46, Loss: 1.2443621158599854\n",
      "Epoch: 47, Loss: 1.2987885475158691\n",
      "Epoch: 48, Loss: 1.0333669185638428\n",
      "Epoch: 49, Loss: 1.1491034030914307\n",
      "Epoch: 50, Loss: 1.0294920206069946\n",
      "Epoch: 51, Loss: 0.8319357633590698\n",
      "Epoch: 52, Loss: 1.2114224433898926\n",
      "Epoch: 53, Loss: 1.160605549812317\n",
      "Epoch: 54, Loss: 1.2325334548950195\n",
      "Epoch: 55, Loss: 1.1359432935714722\n",
      "Epoch: 56, Loss: 0.5735396146774292\n",
      "Epoch: 57, Loss: 0.7724939584732056\n",
      "Epoch: 58, Loss: 0.7174655199050903\n",
      "Epoch: 59, Loss: 1.1079288721084595\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    l_h = train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(test_loader, 0):\n",
    "            embeddings, targets = data\n",
    "            embeddings = embeddings.to(device, dtype=torch.float32)  # Move embeddings to the device\n",
    "            targets = targets.to(device, dtype=torch.long)  # Move targets to the device\n",
    "            outputs = model(embeddings)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n",
      "Accuracy Score = 0.6125\n",
      "F1 Score (Micro) = 0.6125\n",
      "F1 Score (Macro) = 0.5329566168215091\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = test(epoch)\n",
    "    results = np.array([np.argmax(inner) for inner in outputs])\n",
    "    accuracy = accuracy_score(targets, results)\n",
    "    f1_score_micro = f1_score(targets, results, average='micro')\n",
    "    f1_score_macro = f1_score(targets, results, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick base pre-trained model\n",
    "\n",
    "# define feature extraction layer(docking layer to classification head), usually \"bottle-neck layer\"(last layer before flatten op)\n",
    "\n",
    "#Feature extraction\n",
    "#In this step, you will freeze the convolutional base created from the previous step and to use as a feature extractor\n",
    "# #Additionally, you add a classifier on top of it and train the top-level classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classification head (class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [tensor.item() for tensor in tensor_list]\n",
    "\n",
    "# Plot the values\n",
    "plt.plot(values, marker='o')\n",
    "plt.title(\"Graph of Extracted Values\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# training & Validation Loss\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Training & Validation F1-score\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# training & Validation Loss\n",
    "# Training & Validation F1-score\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be done if we finish the bert model on time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment-deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
